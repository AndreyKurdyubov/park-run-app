import os
import streamlit as st
import requests
from bs4 import BeautifulSoup
from sqlalchemy import create_engine, text
from datetime import datetime
import pandas as pd  
import aiohttp
import asyncio
from aiohttp import ClientTimeout
from asyncio import Semaphore
from utils import menu

#####################################################################################################################################################
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
#####################################################################################################################################################

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title='Ducküå≥Run', page_icon=':running:')

menu()

# –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
image_path = 'logo.jpg'

# –í—Å—Ç–∞–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
st.image(image_path, caption='')

# –°–∫—Ä—ã—Ç–∏–µ —Ñ—É—Ç–µ—Ä–∞ –∏ –º–µ–Ω—é
hide_streamlit_style = """
            <style>
            MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            </style>
            """
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
# st.header('–ë–∞–∑–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ 5–í–µ—Ä—Å—Ç –ü–µ—Ç–µ—Ä–≥–æ—Ñ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–∏–π—Å–∫–∏–π')

st.divider()

col1, col2 = st.columns(2)

with col1:
    st.subheader('–°–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü:')
    # st.page_link("pages_dir\main_table.py", label="–ë–∞–∑–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤")
    # st.page_link("pages_dir\records_table.py", label="–ö–ª—É–±—ã –∏ —Ä–µ–∫–æ—Ä–¥—ã")
    st.markdown('''
    - [–ë–∞–∑–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤](main_table)
    - [–ö–ª—É–±—ã –∏ —Ä–µ–∫–æ—Ä–¥—ã](records_table)
    - [–ü–æ—á—Ç–∏ –≤ –∫–ª—É–±–µ](almost_club)
    - [–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã](last_results)
    ''')

#####################################################################################################################################################
# –ü–∞—Ä—Å–∏–Ω–≥
#####################################################################################################################################################

main_url = 'https://5verst.ru/results/latest/'
tarjet_park = '–ü–µ—Ç–µ—Ä–≥–æ—Ñ'  # –ü–µ—Ç–µ—Ä–≥–æ—Ñ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–∏–π—Å–∫–∏–π
target_runs = [tarjet_park]

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
MAX_CONCURRENT_REQUESTS = 10  # –ú–∞–∫—Å–∏–º—É–º 10 –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
TIMEOUT_SECONDS = 30  # –¢–∞–π–º–∞—É—Ç –Ω–∞ –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å - 30 —Å–µ–∫—É–Ω–¥

# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —Ç–∞–π–º–∞—É—Ç–æ–º
async def fetch(session, url, semaphore):
    async with semaphore:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        try:
            async with session.get(url, timeout=ClientTimeout(total=TIMEOUT_SECONDS)) as response:
                return await response.text()
        except asyncio.TimeoutError:
            print(f"Timeout for {url}")
            return None

# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
# https://5verst.ru/results/latest/
async def parse_main_table(session, url, semaphore):
    response_text = await fetch(session, url, semaphore)
    if response_text is None:
        return []

    soup = BeautifulSoup(response_text, 'html.parser')
    table = soup.find('table')
    starts_latest = []

    for row in table.find_all('tr')[1:]:
        cells = row.find_all('td')
        number_cell = cells[0]
        run = number_cell.text.strip().split(' #')[0]
        link = number_cell.find('a')['href'] if number_cell.find('a') else None
        date = cells[1].text.strip()
        starts_latest.append([run, date, link])

    return starts_latest

# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –∑–∞–±–µ–≥–æ–º
# https://5verst.ru/petergofaleksandriysky/results/all/
async def parse_run_page(session, run_link, location_name, semaphore):
    response_text = await fetch(session, run_link, semaphore)
    if response_text is None:
        return []

    soup = BeautifulSoup(response_text, 'html.parser')
    run_table = soup.find('table')
    run_data = []

    for run_row in run_table.find_all('tr')[1:]:
        run_cells = run_row.find_all('td')
        number = run_cells[0].get_text(strip=True)
        date_cell = run_cells[1].get_text(strip=True)
        link = run_cells[1].find('a')['href'] if run_cells[1].find('a') else None
        finishers = int(run_cells[2].get_text(strip=True))
        volunteers = int(run_cells[3].get_text(strip=True))
        avg_time = run_cells[4].get_text(strip=True)
        best_female_time = run_cells[5].get_text(strip=True)
        best_male_time = run_cells[6].get_text(strip=True)
        
        if number:
            run_data.append([location_name, number, date_cell, link, finishers, volunteers, avg_time, best_female_time, best_male_time])

    return run_data

# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∏ –≤–æ–ª–æ–Ω—Ç—ë—Ä–æ–≤
async def parse_participant_and_volunteer_tables(session, run_protocol_link, run_info, semaphore):
    response_text = await fetch(session, run_protocol_link, semaphore)
    if response_text is None:
        return [], []

    soup = BeautifulSoup(response_text, 'html.parser')
    all_tables = soup.find_all('table')

    # –ó–∞–±–µ–≥: location_name, number, date_cell, link, finishers, volunteers, avg_time, best_female_time, best_male_time
    location_name, number, date_cell, link, finishers, volunteer_count, avg_time, best_female_time, best_male_time = run_info

    participants_data = []
    volunteers_data = []

    # –ü–∞—Ä—Å–∏–º —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
    participant_table = all_tables[0]
    for row in participant_table.find_all('tr')[1:]:
        cells = row.find_all('td')
        if len(cells) >= 4:
            position = cells[0].get_text(strip=True)
            name_tag = cells[1].find('a')
            name = name_tag.get_text(strip=True) if name_tag else '‚Äî'
            name_lc = name.lower()
            profile_link = name_tag['href'] if name_tag else '‚Äî'
            participant_id = profile_link.split('/')[-1] if profile_link != '‚Äî' else '‚Äî'
            stats_div = cells[1].find('div', class_='user-stat')
            finishes = '‚Äî'
            volunteers = '‚Äî'
            if stats_div:
                stats_spans = stats_div.find_all('span')
                finishes = stats_spans[0].get_text(strip=True).split(' ')[0] if len(stats_spans) > 0 else '‚Äî'
                volunteers = stats_spans[1].get_text(strip=True).split(' ')[0] if len(stats_spans) > 1 else '‚Äî'
            club_tags = cells[1].find_all('span', class_='club-icon')
            clubs = ', '.join([club['title'] for club in club_tags]) if club_tags else '‚Äî'
            age_group = cells[2].get_text(strip=True).split(' ')[0] if cells[2] else '‚Äî'
            age_grade_tag = cells[2].find('div', class_='age_grade')
            age_grade = age_grade_tag.get_text(strip=True) if age_grade_tag else '‚Äî'
            time = cells[3].get_text(strip=True) if cells[3] else '‚Äî'
            achievements = []
            achievements_div = cells[3].find('div', class_='table-achievments')
            if achievements_div:
                achievement_icons = achievements_div.find_all('span', class_='results_icon')
                for icon in achievement_icons:
                    achievements.append(icon['title'])
            participants_data.append([location_name, number, date_cell, link, finishers, volunteer_count, avg_time, best_female_time, best_male_time,
                                      position, name, name_lc, profile_link, participant_id, clubs, finishes, volunteers, age_group, age_grade, time, ', '.join(achievements)])
            
    # –ü–∞—Ä—Å–∏–º –≤–æ–ª–æ–Ω—Ç—ë—Ä–æ–≤
    volunteer_table = all_tables[1]
    for row in volunteer_table.find_all('tr')[1:]:
        columns = row.find_all('td')
        if len(columns) > 1:
            name_tag = columns[0].find('a')
            name = name_tag.get_text(strip=True) if name_tag else '‚Äî'
            name_lc = name.lower()
            profile_link = name_tag['href'] if name_tag else '‚Äî'
            participant_id = profile_link.split('/')[-1] if profile_link != '‚Äî' else '‚Äî'
            stats_div = columns[0].find('div', class_='user-stat')
            finishes = '‚Äî'
            volunteers = '‚Äî'
            if stats_div:
                stats_spans = stats_div.find_all('span')
                finishes = stats_spans[0].get_text(strip=True).split(' ')[0] if len(stats_spans) > 0 else '‚Äî'
                volunteers = stats_spans[1].get_text(strip=True).split(' ')[0] if len(stats_spans) > 1 else '‚Äî'
            club_tags = columns[0].find_all('span', class_='club-icon')
            clubs = ', '.join([club['title'] for club in club_tags]) if club_tags else '‚Äî'
            volunteer_role_info = columns[1].find('div', class_='volunteer__role')
            if volunteer_role_info:
                first_volunteer_tag = volunteer_role_info.find('span', class_='results_icon')
                first_volunteer_info = first_volunteer_tag['title'] if first_volunteer_tag else '‚Äî'
                role_tag = volunteer_role_info.find_all('span')
                volunteer_role = role_tag[-1].get_text(strip=True) if role_tag else '‚Äî'
            else:
                first_volunteer_info = '‚Äî'
                volunteer_role = '‚Äî'
            volunteers_data.append([location_name, number, date_cell, link, finishers, volunteer_count, avg_time, best_female_time, best_male_time,
                                    name, name_lc, profile_link, participant_id, finishes, volunteers, clubs, volunteer_role, first_volunteer_info])
    
    return participants_data, volunteers_data

# –û—Å–Ω–æ–≤–Ω–∞—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∑–∞–±–µ–≥–æ–≤
async def get_full_run_data(main_url, target_runs):
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)  # –°–æ–∑–¥–∞—ë–º —Å–µ–º–∞—Ñ–æ—Ä

    async with aiohttp.ClientSession() as session:
        # –ü–∞—Ä—Å–∏–º –æ—Å–Ω–æ–≤–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
        starts_latest = await parse_main_table(session, main_url, semaphore)
        filtered_runs = [run for run in starts_latest if any(location in run[0] for location in target_runs)]

        all_participant_data = []
        all_volunteer_data = []

        # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –∑–∞–±–µ–≥
        for run in filtered_runs:
            run_link = run[2]
            location_name = run[0]
            run_data = await parse_run_page(session, run_link, location_name, semaphore)

            # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∏ –≤–æ–ª–æ–Ω—Ç—ë—Ä–æ–≤
            tasks = [
                parse_participant_and_volunteer_tables(session, run_info[3], run_info, semaphore)
                for run_info in run_data if run_info[3]
            ]
            results = await asyncio.gather(*tasks)

            # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for participants, volunteers in results:
                all_participant_data.extend(participants)
                all_volunteer_data.extend(volunteers)

        return all_participant_data, all_volunteer_data
    
# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —É—á–∞—Å—Ç–Ω–∏–∫–∞
async def parse_participant_page(participant_link, session, semaphore):
    html = await fetch(session, participant_link, semaphore)
    if html is None:
        return []  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    soup = BeautifulSoup(html, 'html.parser')
    stats_data = []

    # –ù–∞–π–¥—ë–º div —Å –Ω—É–∂–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
    stats_div = soup.find('div', class_='grid grid-cols-2 gap-px bg-black/[0.05]')
    if stats_div:
        stats_items = stats_div.find_all('div', class_='bg-white p-4')

        finishes = stats_items[0].find('span', class_='text-3xl font-semibold tracking-tight').text.strip() if len(stats_items) > 0 else 'N/A'
        volunteers = stats_items[1].find('span', class_='text-3xl font-semibold tracking-tight').text.strip() if len(stats_items) > 1 else 'N/A'
        best_time = stats_items[2].find('span', class_='text-3xl font-semibold tracking-tight').text.strip() if len(stats_items) > 2 else 'N/A'
        best_time_link = stats_items[2].find('a', class_='user-info-park-link')['href'] if len(stats_items) > 2 and stats_items[2].find('a', class_='user-info-park-link') else 'N/A'

        clubs = stats_items[3].find_all('span', class_='club-icon') if len(stats_items) > 3 else []
        clubs_titles = ', '.join([club['title'] for club in clubs])
    else:
        finishes = volunteers = best_time = best_time_link = 'N/A'
        clubs_titles = ''

    peterhof_finishes_count = peterhof_volunteers_count = 0   # by default

    # –ù–∞–π–¥—ë–º —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –∑–∞–±–µ–≥–æ–≤ –≤ –ü–µ—Ç–µ—Ä–≥–æ—Ñ–µ
    tables = soup.find_all('table')
    if tables:
        vol_tab = 1  # –ø–æ –¥–µ—Ñ–æ–ª—Ç—É, –≤–æ–ª–æ–Ω—Ç–µ—Ä—Å—Ç–≤–∞ –∏–¥—É—Ç –≤—Ç–æ—Ä–æ–π —Ç–∞–±–ª–∏—Ü–µ–π
        second_time = None  #  second best time
        # –ü–æ–¥—Å—á—ë—Ç —Ñ–∏–Ω–∏—à–µ–π –≤ –ü–µ—Ç–µ—Ä–≥–æ—Ñ–µ
        if len(tables) > 1:  # –µ—Å—Ç—å —Ñ–∏–Ω–∏—à–∏
            peterhof_finishes_count = sum(1 for row in tables[0].find_all('tr')[1:] if tarjet_park in row.find_all('td')[1].text.strip()) if len(tables) > 0 else 0
            times = [row.find_all('td')[2].text.strip() for row in tables[0].find_all('tr')[2:]]  # list of all finish times except first 
            if len(times) > 0:
                second_time = min(times)
        else: # –Ω–µ—Ç —Ñ–∏–Ω–∏—à–µ–π
            vol_tab = 0  # –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ —Ç–∞–±–ª–∏—Ü–∞ –≤–æ–ª–æ–Ω—Ç–µ—Ä—Å—Ç–≤  
        
        # –î–ª—è –≤–æ–ª–æ–Ω—Ç—ë—Ä—Å—Ç–≤ —Å–æ–∑–¥–∞—ë–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–∞—Ç
        peterhof_volunteer_dates = set()

        if len(tables) != 2: # –µ—Å–ª–∏ –µ—Å—Ç—å –≤–æ–ª–æ–Ω—Ç–µ—Ä—Å—Ç–≤–∞, —Ç–æ —á–∏—Å–ª–æ —Ç–∞–±–ª–∏—Ü –Ω–µ 2
            for row in tables[vol_tab].find_all('tr')[1:]:
                location = row.find_all('td')[1].text.strip()
                if tarjet_park in location:
                    date = row.find_all('td')[0].text.strip()  # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É
                    peterhof_volunteer_dates.add(date)  # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞—Ç—É –≤ –º–Ω–æ–∂–µ—Å—Ç–≤–æ (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–∞—Ç—ã)
        peterhof_volunteers_count = len(peterhof_volunteer_dates)  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–∞—Ç –≤–æ–ª–æ–Ω—Ç—ë—Ä—Å—Ç–≤
      
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    stats_data.append([best_time, second_time, finishes, peterhof_finishes_count, volunteers, peterhof_volunteers_count, clubs_titles, best_time_link])
    return stats_data

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
async def get_all_stats_data(df_runners, df_orgs):
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    all_stats_data = []
    run_links = df_runners['profile_link']
    org_links = df_orgs['profile_link']  # –Ω—É–∂–Ω–æ –∏—Å–∫–∞—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ –±–µ–≥—É–Ω–∞–º, –Ω–æ –∏ –ø–æ –≤–æ–ª–æ–Ω—Ç–µ—Ä–∞–º. 

    # –ü—Ä–æ–π–¥–µ–º—Å—è –ø–æ –∫–∞–∂–¥–æ–º—É —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É —É—á–∞—Å—Ç–Ω–∏–∫—É
    unique_links = [link for link in pd.concat([run_links, org_links]).unique() if '5verst.ru/userstats' in link]

    semaphore = Semaphore(MAX_CONCURRENT_REQUESTS)  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

    async with aiohttp.ClientSession() as session:
        tasks = []
        for link in unique_links:
            tasks.append(parse_participant_page(link, session, semaphore))

        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        results = await asyncio.gather(*tasks)

        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        for link, parsed_data in zip(unique_links, results):
            if parsed_data:  # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã
                try:
                    participant_row = df_runners[df_runners['profile_link'] == link].iloc[0]
                    sex = participant_row['age_group'][0]
                    if sex not in ['–ú', '–ñ']:
                        sex = None
                except IndexError:
                    participant_row = df_orgs[df_orgs['profile_link'] == link].iloc[0] # –µ—Å–ª–∏ —É—á–∞—Å—Ç–Ω–∏–∫ —Ç–æ–ª—å–∫–æ –≤ –≤–æ–ª–æ–Ω—Ç–µ—Ä–∞—Ö
                    sex = None

                name = participant_row['name']
                name_lc = participant_row['name_lc']
                profile_link = participant_row['profile_link']
                participant_id = participant_row['participant_id']

                if sex == None:
                    sex_exception = {'–ú–∏—Ö–∞–∏–ª': '–ú', '–ê–Ω–¥—Ä–µ–π': '–ú', '–Æ—Ä–∏–π': '–ú', '–ê–Ω–∞—Ç–æ–ª–∏–π': '–ú', '–ò—Ä–∏–Ω–∞': '–ñ', '–û–ª–µ–≥': '–ú', '–ê–Ω—Ç–æ–Ω': '–ú', '–í–µ—Ä–∞': '–ñ', '–î–∞—Ä—å—è': '–ñ', '–ö–∏—Ä–∏–ª–ª': '–ú', '–ú–∞—Ä–∏—è': '–ñ', '–ê–ª–µ–∫—Å–∞–Ω–¥—Ä': '–ú', '–°–∞–º–∞—Ç': '–ú', '–ï–≤–≥–µ–Ω–∏—è': '–ñ', 
                    '–¢–∏–º–æ—Ñ–µ–π': '–ú', '–í–∞—Ä–≤–∞—Ä–∞': '–ñ', '–¢–∞—Ç—å—è–Ω–∞': '–ñ', '–Æ–ª–∏—è': '–ñ', '–ê–Ω–Ω–∞': '–ñ', '–ê–ª–µ–∫—Å–µ–π': '–ú', '–ü–æ–ª–∏–Ω–∞': '–ñ', 'Liubov': '–ñ', '–ù–∏–∫–æ–ª–∞–π': '–ú', '–ï–ª–∏–∑–∞–≤–µ—Ç–∞': '–ñ', '–°–æ—Ñ–∏—è': '–ñ', '–ê–Ω–∞—Å—Ç–∞—Å–∏—è': '–ñ', '–°—Ç–∞–Ω–∏—Å–ª–∞–≤–∞': '–ñ', 
                    '–ú–∞—Ä–≥–∞—Ä–∏—Ç–∞': '–ñ', '–≠–ª–ª–∏–Ω–∞': '–ñ', '–°–≤–µ—Ç–ª–∞–Ω–∞': '–ñ', '–ö—Å–µ–Ω–∏—è': '–ñ', '–°—Ç–∞–Ω–∏—Å–ª–∞–≤': '–ú', '–ò–≤–∞–Ω': '–ú', '–†—É—Å–ª–∞–Ω': '–ú', '–û–ª—å–≥–∞': '–ñ', '–Ø—Ä–æ—Å–ª–∞–≤': '–ú', '–ß–µ—Ä–Ω—è–µ–≤': '–ú', '–ê–Ω—Ç–æ–Ω–∏–Ω–∞': '–ñ', '–ê—Ä—Ç—ë–º': '–ú'}
                    first_name = name.split()[0]
                    sex = sex_exception.get(first_name)  # sex or None

                # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫, –≤–∫–ª—é—á–∞—è –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã df_runners
                for data in parsed_data:
                    all_stats_data.append([name, name_lc, sex, profile_link, participant_id] + data)

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ –¥–∞–Ω–Ω—ã—Ö
    return all_stats_data

#####################################################################################################################################################
# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–∞–∑—É –î–∞–Ω–Ω—ã—Ö
#####################################################################################################################################################

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
def save_to_database(df_runners, df_orgs, df_stats, db_url='sqlite:///mydatabase.db'):
    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    engine = create_engine(db_url)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –±–µ–≥—É–Ω–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü—É 'runners'
    df_runners.to_sql('runners', con=engine, if_exists='replace', index=False)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü—É 'organizers'
    df_orgs.to_sql('organizers', con=engine, if_exists='replace', index=False)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –±–µ–≥—É–Ω–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü—É 'runners'
    df_stats.to_sql('users', con=engine, if_exists='replace', index=False)

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –±–¥
async def update_data():
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –≤—Å–µ—Ö —É—á–∞—Å—Ç–Ω–∏–∫–∞—Ö –∏ –≤–æ–ª–æ–Ω—Ç—ë—Ä–∞—Ö
    all_participant_data, all_volunteer_data = await get_full_run_data(main_url, target_runs)

    # –°–æ–∑–¥–∞—ë–º DataFrame –¥–ª—è –±–µ–≥—É–Ω–æ–≤
    df_runners = pd.DataFrame(all_participant_data, columns=[
        'run', 'run_number', 'run_date', 'run_link', 'finisher', 'volunteer', 'avg_time',
        'best_female_time', 'best_male_time', 'position', 'name', 'name_lc', 'profile_link',
        'participant_id', 'clubs', 'finishes', 'volunteers', 'age_group', 'age_grade',
        'time', 'achievements'
    ])
    df_runners['run_date'] = pd.to_datetime(df_runners['run_date'], dayfirst=True)

    # –°–æ–∑–¥–∞—ë–º DataFrame –¥–ª—è –≤–æ–ª–æ–Ω—Ç—ë—Ä–æ–≤
    df_orgs = pd.DataFrame(all_volunteer_data, columns=[
        'run', 'run_number', 'run_date', 'run_link', 'finisher', 'volunteer', 'avg_time',
        'best_female_time', 'best_male_time', 'name', 'name_lc', 'profile_link', 'participant_id',
        'finishes', 'volunteers', 'clubs', 'volunteer_role', 'first_volunteer_info'
    ])
    # df_orgs = (
    #     df_orgs.groupby([col for col in df_orgs.columns if col != 'volunteer_role'])['volunteer_role']
    #     .apply(lambda x: ', '.join(x))
    #     .reset_index()
    # )
    df_orgs['run_date'] = pd.to_datetime(df_orgs['run_date'], dayfirst=True)

    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
    all_stats_data = await get_all_stats_data(df_runners, df_orgs)

    # –°–æ–∑–¥–∞—ë–º DataFrame –¥–ª—è –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    df_stats = pd.DataFrame(all_stats_data, columns=[
        'name', 'name_lc', 'sex', 'profile_link', 'participant_id', 'best_time', 'second_time', 'finishes', 
        'peterhof_finishes_count', 'volunteers', 'peterhof_volunteers_count', 
        'clubs_titles', 'best_time_link'
    ])

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    save_to_database(df_runners, df_orgs, df_stats)

#####################################################################################################################################################
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
#####################################################################################################################################################

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç—ã –∏–∑ —Å–∞–π—Ç–∞
def get_last_date_from_site():
    url = 'https://5verst.ru/petergofaleksandriysky/results/all/'
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    cell_date = soup.find_all('table')[0].find_all('tr')[1].find_all('td')[1]
    last_date = cell_date.text.strip()
    link = cell_date.find('a')['href']
    # print(link)

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ last_date –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ DD.MM.YYYY –≤ –æ–±—ä–µ–∫—Ç datetime
    last_date_site = datetime.strptime(last_date, '%d.%m.%Y').date()
    return last_date_site, link

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–∞—Ç—ã –∏–∑ –ë–î
def get_last_date_from_db(db_url='sqlite:///mydatabase.db'):
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    db_path = db_url.replace('sqlite:///', '')  # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    if not os.path.exists(db_path):
        return None  # –ï—Å–ª–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
    
    try:
        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        engine = create_engine(db_url)
        with engine.connect() as connection:
            query = text("SELECT MAX(run_date) FROM runners;")  # –ó–∞–º–µ–Ω–∏—Ç—å run_date –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–µ –∏–º—è –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–æ–π
            result = connection.execute(query)
            last_date_db = result.scalar()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ last_date_db –Ω–µ None, —Ç–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫—É –≤ –¥–∞—Ç—É
            if last_date_db:
                last_date_db = datetime.strptime(last_date_db, '%Y-%m-%d %H:%M:%S.%f').date()
            else:
                last_date_db = None
    except Exception as e:
        st.write(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
        return None
    return last_date_db


last_date_site, last_results_link = get_last_date_from_site()
last_date_db = get_last_date_from_db()
    
with col2:
    st.subheader('–ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö:')  
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ last_date_db –Ω–µ –ø—É—Å—Ç–∞—è
    if last_date_db is None:
        st.write('–î–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑–µ –Ω–µ—Ç!')
        if st.button('–û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ'):
            st.write('–ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö...')
            asyncio.run(update_data())
            st.success('–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö!')
    else:
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–∞—Ç
        if last_date_db != last_date_site:
            st.write(f'–î–∞–Ω–Ω—ã–µ —É—Å—Ç–∞—Ä–µ–ª–∏. –î–∞—Ç–∞ –≤ –±–∞–∑–µ: {last_date_db}, –¥–∞—Ç–∞ –Ω–∞ —Å–∞–π—Ç–µ: [{last_date_site}]({last_results_link}).')
             
            if st.button('–û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ'):
                st.write('–ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö...')
                asyncio.run(update_data())
                st.success('–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö!')
        else:
            st.markdown(f'''–î–∞–Ω–Ω—ã–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã üëç  
                        –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {last_date_db}  
                        –ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞ –Ω–∞ —Å–∞–π—Ç–µ: [{last_date_site}]({last_results_link})
                        ''')

#####################################################################################################################################################
# –ü–æ–∏—Å–∫ –ø–æ –∏–º–µ–Ω–∏
#####################################################################################################################################################
def go_search_by_role(option, engine):
    sql_query = text(f'''SELECT name, 
                                COUNT(*) as number, 
                                volunteer_role, 
                                MAX(run_date) as last_date_of_role,
                                profile_link
                        FROM organizers
                        WHERE volunteer_role LIKE "%{option}%" AND run_number != ''
                        GROUP BY profile_link;
                     ''')
    try:
        with engine.connect() as connection:
            result = connection.execute(sql_query).fetchall()

        if result:
            df_results = pd.DataFrame(result)
            df_results['last_date_of_role'] = pd.to_datetime(df_results['last_date_of_role']).dt.date

            with st.container():
                st.data_editor(
                    df_results,
                    column_config={
                        'profile_link': st.column_config.LinkColumn(label="id 5–í—ë—Ä—Å—Ç", display_text=r"([0-9]*)$", width='100px'),
                        'name': st.column_config.Column(label="–ò–º—è", width='120px'), 
                        # 'best_time': st.column_config.Column(label="–õ—É—á—à–µ–µ –≤—Ä–µ–º—è", width='100px'),
                        # 'finishes': st.column_config.Column(label="# —Ñ–∏–Ω–∏—à–µ–π", width='100px'),
                        # 'peterhof_finishes_count': st.column_config.Column(label="# —Ñ–∏–Ω–∏—à–µ–π –≤ –ü–µ—Ç–µ—Ä–≥–æ—Ñ–µ", width='150px'),
                        'volunteer_role': st.column_config.Column(label="–†–æ–ª—å", width='medium'),
                        'number': st.column_config.Column(label="#", width='small'),
                        'last_date_of_role': st.column_config.Column(label="–ü–æ—Å–ª–µ–¥–Ω—è—è –¥–∞—Ç–∞", width='medium'),
                        # 'peterhof_volunteers_count': st.column_config.Column(label="# –≤–æ–ª–æ–Ω—Ç–µ—Ä—Å—Ç–≤ –≤ –ü–µ—Ç–µ—Ä–≥–æ—Ñ–µ", width='150px'),
                        # 'clubs_titles': st.column_config.Column(label="–ö–ª—É–±—ã", width='large'),
                    },
                    hide_index=True,
                    key="roles"
                )
        else:
            st.write("–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É.")

    except Exception as e:
        st.write(f"–û—à–∏–±–∫–∞ {e}")


def go_search_by_name(search_query, engine):
    # –û—á–∏—Å—Ç–∫–∞ –≤–≤–æ–¥–∞
    words = ' '.join(search_query.strip().split()).lower()
    if not words: 
        return

    # st.write(f'–ü–æ–∏—Å–∫–æ–≤—ã–µ —Å–ª–æ–≤–∞: {words}')
    # –§–æ—Ä–º–∏—Ä—É–µ–º —É—Å–ª–æ–≤–∏—è –ø–æ–∏—Å–∫–∞
    conditions = " OR ".join([f"name_lc LIKE :word{i}" for i in range(len(words.lower().split()))])
    sql_query = text(f'''SELECT profile_link, 
                                name, 
                                best_time, 
                                finishes, 
                                peterhof_finishes_count, 
                                volunteers, 
                                peterhof_volunteers_count, 
                                clubs_titles 
                    FROM users 
                    WHERE {conditions}''')
    params = {f"word{i}": f"%{word}%" for i, word in enumerate(words.split())}

    # st.write(f'SQL –∑–∞–ø—Ä–æ—Å: {sql_query}')
    # st.write(f'–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {params}')

    try:
        with engine.connect() as connection:
            result = connection.execute(sql_query, params).fetchall()

        if result:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ DataFrame
            df_results = pd.DataFrame(result)
            with st.container():
                st.data_editor(
                    df_results,
                    column_config={
                        'profile_link': st.column_config.LinkColumn(label="id 5–í—ë—Ä—Å—Ç", display_text=r"([0-9]*)$", width='100px'),
                        'name': st.column_config.Column(label="–ò–º—è", width='120px'), 
                        'best_time': st.column_config.Column(label="–õ—É—á—à–µ–µ –≤—Ä–µ–º—è", width='100px'),
                        'finishes': st.column_config.Column(label="# —Ñ–∏–Ω–∏—à–µ–π", width='100px'),
                        'peterhof_finishes_count': st.column_config.Column(label="# —Ñ–∏–Ω–∏—à–µ–π –≤ –ü–µ—Ç–µ—Ä–≥–æ—Ñ–µ", width='150px'),
                        'volunteers': st.column_config.Column(label="# –≤–æ–ª–æ–Ω—Ç–µ—Ä—Å—Ç–≤", width='120px'),
                        'peterhof_volunteers_count': st.column_config.Column(label="# –≤–æ–ª–æ–Ω—Ç–µ—Ä—Å—Ç–≤ –≤ –ü–µ—Ç–µ—Ä–≥–æ—Ñ–µ", width='150px'),
                        'clubs_titles': st.column_config.Column(label="–ö–ª—É–±—ã", width='large'),
                    },
                    hide_index=True,
                    key="custom_table"
                )
        else:
            st.write("–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É.")

    except Exception as e:
        st.write(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")

def show_search(db_url):
    # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    # db_url = 'sqlite:///mydatabase.db'
    engine = create_engine(db_url)

    querie = '''
    SELECT volunteer_role
    FROM organizers
    '''
    df = pd.read_sql(querie, con=engine)
    array_of_roles = df['volunteer_role'].unique()
    roles = [role.split(', ') for role in array_of_roles]
    unique_roles = []
    for role in roles:
        unique_roles.extend(role)
    
    st.divider()

    st.subheader('–ü–æ–∏—Å–∫ –ø–æ –≤–æ–ª–æ–Ω—Ç–µ—Ä—Å–∫–æ–π —Ä–æ–ª–∏:')

    option = st.selectbox(
    "–ü–æ–∏—Å–∫ –ø–æ –≤–æ–ª–æ–Ω—Ç–µ—Ä—Å–∫–æ–π —Ä–æ–ª–∏",
    options=sorted(set(unique_roles)),
    index=None,
    placeholder="–í—ã–±–µ—Ä–∏—Ç–µ —Ä–æ–ª—å",
    label_visibility='collapsed'
    )

    if option:
        go_search_by_role(option, engine)

    st.divider()

    st.subheader('–ü–æ–∏—Å–∫ —É—á–∞—Å—Ç–Ω–∏–∫–∞ –ø–æ –∏–º–µ–Ω–∏:')

    # –ü–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    search_query = st.text_input('–ü–æ–∏—Å–∫ –ø–æ –∏–º–µ–Ω–∏', 
                                 placeholder="–í–≤–µ–¥–∏—Ç–µ –∏–º—è –∏–ª–∏ —Ñ–∞–º–∏–ª–∏—é", 
                                 label_visibility="collapsed")

    if search_query:
        go_search_by_name(search_query, engine)

db_url='sqlite:///mydatabase.db'
db_path = db_url.replace('sqlite:///', '')  # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

if os.path.exists(db_path):
    show_search(db_url)